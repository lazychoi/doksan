{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8e8075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링 돌리는데 필요한 라이브러리를 import해주세요.\n",
    "# 크롤링 작업을 위한 라이브러리 임포트\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "# 코드 진행 지연을 위한 time 임포트\n",
    "import time\n",
    "# 2022년도 7월 이후 selenium 업데이트로 인한 xpath 추적시 임포트\n",
    "from selenium.webdriver.common.by import By\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1ed365",
   "metadata": {},
   "source": [
    "## 순회 크롤러\n",
    "\n",
    "    - 같은 양식의 페이지를 순회화면서 자료를 수집해오는 크롤러\n",
    "    - 원 페이지 크롤러를 제작한 다음, 완성된 크롤러를 반복문에 넣어서 만든다.\n",
    "    - 반복을 어디부터 돌릴지에 대한 파악이 제일 중요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3cad2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. 1번으로 이동\n",
    "# 금일(22년 10월 13일)기준  45번 반복문을 돌려서 \n",
    "# 다음페이지 xpath를 마지막에 클릭하게 해 주시면 됩니다.\n",
    "driver = webdriver.Chrome()\n",
    "time.sleep(1)\n",
    "driver.get(\"https://product.kyobobook.co.kr/bestseller/online?period=001\")\n",
    "time.sleep(5)\n",
    "#5. txt에 저장(추후 다른 셀에서 진행하고 먼저 리스트에 1000개 내외로 저장해주세요.)\n",
    "# 빈 리스트를 만들어서 제목, 가격, 저자를 전수 저장해줍니다.\n",
    "title_list = []\n",
    "price_list = []\n",
    "author_list = []\n",
    "for i in range(45):\n",
    "    time.sleep(3)\n",
    "    #2. 소스코드 긁어오기\n",
    "    source = driver.page_source\n",
    "    #3. 파싱\n",
    "    parsed_source = BeautifulSoup(source, \"html.parser\")\n",
    "    #4. 원하는 데이터 추출\n",
    "    # 제목만 추출해서 print()로 찍어주세요.\n",
    "    \n",
    "    ##############################################################################\n",
    "    # 전체 코드에서 span태그이면서 클래스속성이 prod_name인 태그만 가져와 저장하기\n",
    "    ####################### 제목 긁어오기 ########################################\n",
    "    span_title_list = parsed_source.find_all(\"span\", class_=\"prod_name\")\n",
    "    # 한 페이지에 있는 책 제목들을 순위대로 하나씩 title에 번갈아가며 저장한 다음\n",
    "    for title in span_title_list:\n",
    "        # 제목 목록 저장하기\n",
    "        title_list.append(title.text.replace(\",\", \"ͺ\"))\n",
    "        \n",
    "    #############################################################################\n",
    "    # 전체 코드에서 span태그이면서 클래스속성이 prod_author인 태그만 가져와 저장하기\n",
    "    ########################저자 긁어오기 #######################################\n",
    "    span_author_list = parsed_source.find_all(\"span\", class_=\"prod_author\")\n",
    "    # 한 페이지에 있는 책 제목들을 순위대로 하나씩 title에 번갈아가며 저장한 다음\n",
    "    for author in span_author_list:\n",
    "        # 작가 목록 저장하기\n",
    "        author_list.append(author.text)        \n",
    "    \n",
    "    \n",
    "    ###########################################################################\n",
    "    # 전체 코드에서 span태그이면서 클래스속성이 price인 태그만 가져와 저장하기\n",
    "    ########################금액 긁어오기 #######################################\n",
    "    span_price_list = parsed_source.find_all(\"span\", class_=\"price\")\n",
    "    # 한 페이지에 있는 책 제목들을 순위대로 하나씩 title에 번갈아가며 저장한 다음\n",
    "    for price in span_price_list:\n",
    "        # 작가 목록 저장하기\n",
    "        price_list.append(price.text)  \n",
    "    \n",
    "    \n",
    "    time.sleep(3)\n",
    "    #1. n페이지 접근\n",
    "    driver.find_element(By.XPATH, '//*[@id=\"tabRoot\"]/div[2]/div[1]/button[2]').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c510d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 슬랙에 보내드린 주소로 접근해 소스코드를 가져왔을때\n",
    "# 해당 코드가 화면에 보이는 페이지 정보와 일치하는지 체크해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9037abfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(price_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38e5abf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab3f91f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(author_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5d6abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. txt에 저장\n",
    "# codecs를 이용해서 kyobo_result.txt를 만들어주세요.\n",
    "# csv로 바꿀 수 있도록 처리해주시면 됩니다.\n",
    "# 순위,제목,저자,가격\n",
    "# 위 양식으로 해주시고, 순위는 그냥 순차적으로 다시 부여해주세요.\n",
    "# 지금 제쪽 PC기준 1000등 책도 그냥 900등으로 기입하면 됩니다.\n",
    "f = codecs.open(\"c:/users/playdata/crawler/kyobo_result2.txt\", encoding=\"utf-8\", mode=\"w\")\n",
    "f.write('순위,제목,저자,가격\\n')\n",
    "for i in range(len(author_list)):\n",
    "    f.write(\"%s,%s,%s,%s\\n\" %((i+1), title_list[i], author_list[i], price_list[i]))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
